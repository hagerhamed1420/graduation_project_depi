{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm7x5MuJPIdu"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub\n",
        "!pip install datasets\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5Tn7FTR3WhZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from huggingface_hub import login\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "\n",
        "\n",
        "import shutil"
      ],
      "metadata": {
        "id": "N5CxRUpuWi2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "login(token=\"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\")"
      ],
      "metadata": {
        "id": "pbM8IQoqn0Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Dataset"
      ],
      "metadata": {
        "id": "rnmEZTDLWpQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "captions\n"
      ],
      "metadata": {
        "id": "gnuhnx2dW3uQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "captions_csv= load_dataset(\"dina301/interior-dataset-captions-en-blip2-opt-2.7b\")\n",
        "\n",
        "print(captions_csv['train'][0])"
      ],
      "metadata": {
        "id": "fVCraHFcWmrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "captions_df = pd.DataFrame(captions_csv['train'])\n",
        "captions_df.to_csv('/content/captions.csv', index=False)"
      ],
      "metadata": {
        "id": "NfRaWRYfWxHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "captions_df.columns\n"
      ],
      "metadata": {
        "id": "-c48KV3jtLTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Images"
      ],
      "metadata": {
        "id": "Sxehso4WW67q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_dir = \"/root/.kaggle\"\n",
        "os.makedirs(kaggle_dir, exist_ok=True)\n",
        "\n",
        "# Replace with your actual API token\n",
        "api_token = {\"username\":\"YOUR_USERNAME\", \"key\":\"YOUR_API_KEY\"}\n",
        "\n",
        "with open(f'{kaggle_dir}/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d stepanyarullin/interior-design-styles --force\n",
        "!unzip interior-design-styles.zip -d /content/"
      ],
      "metadata": {
        "id": "iVLusT2oW-Qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA"
      ],
      "metadata": {
        "id": "TUpWuGz9XACR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "  image_path = captions_csv['train'][i]['image_path'] # Change 'path' to 'image_path'\n",
        "  caption_en = captions_csv['train'][i]['caption_en']\n",
        "\n",
        "  # Construct the full path to the image\n",
        "  full_image_path = os.path.join(\"/content\", image_path)\n",
        "\n",
        "  try:\n",
        "    img = Image.open(full_image_path)\n",
        "    plt.imshow(img)\n",
        "    plt.title(caption_en)\n",
        "    plt.show()\n",
        "  except FileNotFoundError:\n",
        "    print(f\"File not found: {full_image_path}\")\n",
        "  except PIL.UnidentifiedImageError:\n",
        "    print(f\"Could not open or read image file: {full_image_path}\")"
      ],
      "metadata": {
        "id": "cMz6PxmhXCHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#sample from images"
      ],
      "metadata": {
        "id": "qIJkwRkzXGHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_root = \"/content/dataset_train/dataset_train\"\n",
        "target_dir = \"/content/images\"\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "num_images = 1\n",
        "\n",
        "for class_name in os.listdir(source_root):\n",
        "    class_path = os.path.join(source_root, class_name)\n",
        "\n",
        "    if os.path.isdir(class_path):\n",
        "        image_files = [f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        selected_images = image_files[:num_images]\n",
        "        print(selected_images)\n",
        "        for img_name in selected_images:\n",
        "            source_img_path = os.path.join(class_path, img_name)\n",
        "\n",
        "            new_img_name = f\"{class_name}_{img_name}\"\n",
        "            target_img_path = os.path.join(target_dir, new_img_name)\n",
        "\n",
        "            shutil.copy2(source_img_path, target_img_path)\n",
        "\n",
        "print(\"Successfully copied images\")"
      ],
      "metadata": {
        "id": "w1ZoBjqw93oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Load the captions CSV file\n",
        "captions_df = pd.read_csv('/content/captions.csv')\n",
        "\n",
        "# Create the metadata.json file\n",
        "metadata = []\n",
        "\n",
        "# Set image directory\n",
        "image_dir = \"/content/images\"\n",
        "\n",
        "# Iterate through the rows of the DataFrame\n",
        "for index, row in captions_df.iterrows():\n",
        "    original_name = row['image_path'].split('/')[-1]  # e.g., french-country_580.jpg\n",
        "    class_name = original_name.split('_')[0]          # e.g., french-country\n",
        "    new_image_name = f\"{class_name}_{original_name}\"  # e.g., french-country_french-country_580.jpg\n",
        "    image_path = os.path.join(image_dir, new_image_name)\n",
        "\n",
        "    print(image_path)\n",
        "    if os.path.exists(image_path):\n",
        "        metadata_item = {\n",
        "            \"file_name\": new_image_name,\n",
        "            \"prompt\": row['caption_en'],\n",
        "        }\n",
        "        metadata.append(metadata_item)\n",
        "    else:\n",
        "        print(f\"Image not found: {image_path}\")\n",
        "\n",
        "# Save the metadata to metadata.json\n",
        "with open('/content/metadata.json', 'w') as f:\n",
        "    json.dump(metadata, f, indent=4)\n",
        "\n",
        "print(\"‚úÖ metadata.json created successfully.\")\n"
      ],
      "metadata": {
        "id": "PvlcXM2wNb1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "image_dir = \"/content/images\"\n",
        "\n",
        "image_count = len([\n",
        "    f for f in os.listdir(image_dir)\n",
        "    if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
        "])\n",
        "\n",
        "print(image_count)\n"
      ],
      "metadata": {
        "id": "LdIUM5_tRWzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Model"
      ],
      "metadata": {
        "id": "X1DlCEOqeD-v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Dependencies\n"
      ],
      "metadata": {
        "id": "uPNy8zqmeJ2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes transformers accelerate peft -q\n"
      ],
      "metadata": {
        "id": "n9fPNid8eGAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/diffusers.git -q\n"
      ],
      "metadata": {
        "id": "ENeA3-NzeG4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DreamBooth training script tailored for SDXL"
      ],
      "metadata": {
        "id": "tZ5c_03FeOsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/huggingface/diffusers/main/examples/dreambooth/train_dreambooth_lora_sdxl.py\n"
      ],
      "metadata": {
        "id": "DlkieN8deG1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "KaoGifm-eGy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rm -rf ~/.local/share/Trash/*"
      ],
      "metadata": {
        "id": "EuN7Za3ATZtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rm -rf ~/.cache/huggingface/"
      ],
      "metadata": {
        "id": "AobjbJ38WIJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!accelerate config default"
      ],
      "metadata": {
        "id": "zm8-H5Mqeb2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rm -rf dataset_test dataset_train sample_data interior-design-styles.zip"
      ],
      "metadata": {
        "id": "f5edTi00Ov1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rm -rf captions.csv test_labels.csv"
      ],
      "metadata": {
        "id": "xtgBHausXYft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()\n",
        "#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"
      ],
      "metadata": {
        "id": "7gRe7MwZefCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "output_dir = \"/content/corgi_house_LoRA\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(f\"üìÅ Created (or verified) folder: {output_dir}\")\n"
      ],
      "metadata": {
        "id": "1IKFKpMTiPHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Please Create corgi_house_LoRA#"
      ],
      "metadata": {
        "id": "io-1WX0Bupml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch train_dreambooth_lora_sdxl.py \\\n",
        "  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\" \\\n",
        "  --pretrained_vae_model_name_or_path=\"madebyollin/sdxl-vae-fp16-fix\" \\\n",
        "  --instance_data_dir=\"/content/images\" \\\n",
        "  --output_dir=\"/content/corgi_house_LoRA\" \\\n",
        "  --instance_prompt=\"a photo of a sks corgi in a house\" \\\n",
        "  --caption_column=\"prompt\" \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=2 \\\n",
        "  --gradient_checkpointing \\\n",
        "  --learning_rate=1e-4 \\\n",
        "  --snr_gamma=5.0 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --max_train_steps=9 \\\n",
        "  --checkpointing_steps=3 \\\n",
        "  --checkpoints_total_limit=4 \\\n",
        "  --seed=0 \\\n",
        "  --validation_prompt=\"a photo of a sks corgi in a house\" \\\n",
        "  --num_validation_images=1\n"
      ],
      "metadata": {
        "id": "LUGtaoIMehdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#UPload Model weights"
      ],
      "metadata": {
        "id": "o8CO8ss9fKtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import upload_file\n",
        "import os\n",
        "\n",
        "def upload_all_files(repo_id, folder_path):\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            full_path = os.path.join(root, file)\n",
        "            relative_path = os.path.relpath(full_path, folder_path)\n",
        "            upload_file(\n",
        "                repo_id=repo_id,\n",
        "                path_or_fileobj=full_path,\n",
        "                path_in_repo=relative_path,\n",
        "                commit_message=f\"Upload {relative_path}\"\n",
        "            )\n",
        "\n",
        "upload_all_files(\"dina301/Fine-Tuning-SDXL-lora-model\", \"./corgi_house_LoRA\")\n"
      ],
      "metadata": {
        "id": "Mh0YKIaVfXKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#inferance"
      ],
      "metadata": {
        "id": "T86C9zJrfaV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionXLPipeline, AutoencoderKL\n",
        "import torch\n",
        "import os\n",
        "\n",
        "#Identify the paths\n",
        "base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "vae_id = \"madebyollin/sdxl-vae-fp16-fix\"\n",
        "checkpoint_dir = \"/content/corgi_house_LoRA/checkpoint-50\"\n",
        "\n",
        "\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "    base_model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\",\n",
        "    use_safetensors=True,\n",
        ")\n",
        "\n",
        "\n",
        "pipe.vae = AutoencoderKL.from_pretrained(\n",
        "    vae_id,\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "\n",
        "pipe.load_lora_weights(checkpoint_dir)\n",
        "\n",
        "\n",
        "pipe.to(\"cuda\")\n",
        "\n",
        "\n",
        "prompt = \"a photo of TOK home interior, modern living room, soft lighting\"\n",
        "image = pipe(prompt=prompt).images[0]\n",
        "\n",
        "\n",
        "image.show()\n",
        "\n",
        "\n",
        "image.save(\"inference_result.png\")\n"
      ],
      "metadata": {
        "id": "wUufygGngCuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"a photo of TOK home interior, bathroom with black walls\"\n",
        "image = pipe(prompt=prompt).images[0]\n",
        "\n",
        "image.show()\n",
        "\n",
        "image.save(\"inference_result3.png\")"
      ],
      "metadata": {
        "id": "_jmaePGjruZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt =\"A central L-shaped beige sofa with layered linen throws and textured cushions, a low-profile matte black coffee table with ceramic vases and dried pampas grass. Wall-mounted bookshelves with a curated selection of design books and indoor plants like monstera and snake plant. Suspended linear pendant lighting with brass accents above the sitting area, and a large abstract painting in earthy tones on the main wall. Subtle ambient LED lighting integrated into ceiling coves. Nordic-inspired decor elements, clean lines, and a harmonious blend of functionality and elegance. Photorealistic, ultra-detailed, wide-angle lens, cinematic lighting, 8k resolution\"\n",
        "image = pipe(prompt=prompt).images[0]\n",
        "\n",
        "image.show()\n",
        "\n",
        "image.save(\"inference_result4.png\")"
      ],
      "metadata": {
        "id": "c3Vfk_d8tNjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "repo_id = \"dina301/Fine-Tuning-SDXL-lora-model\"\n",
        "local_dir = \"./corgi_house_LoRA\"\n",
        "\n",
        "snapshot_download(\n",
        "    repo_id=repo_id,\n",
        "    local_dir=local_dir,\n",
        "    local_dir_use_symlinks=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "UgMfD8O2aaCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deployment**"
      ],
      "metadata": {
        "id": "bw0U43DNCErw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/corgi_house_LoRA\"\n"
      ],
      "metadata": {
        "id": "uQHDRnvPCIU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio --quiet\n"
      ],
      "metadata": {
        "id": "G3sQyVsECIR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from diffusers import StableDiffusionXLPipeline, LCMScheduler\n",
        "import torch\n",
        "\n",
        "# Load the model\n",
        "base_model = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "    base_model,\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\"\n",
        ").to(\"cuda\")\n",
        "\n",
        "#Load LoRA\n",
        "pipe.load_lora_weights(\"/content/corgi_house_LoRA/checkpoint-9\", weight_name=\"pytorch_lora_weights.safetensors\")\n",
        "\n",
        "#gen image\n",
        "def generate_image(prompt):\n",
        "    image = pipe(prompt).images[0]\n",
        "    return image\n",
        "\n",
        "# Gradio interface\n",
        "gr.Interface(\n",
        "    fn=generate_image,\n",
        "    inputs=gr.Textbox(label=\"Prompt\", placeholder=\"a photo of a sks corgi in a house\"),\n",
        "    outputs=gr.Image(type=\"pil\"),\n",
        "    title=\"Style Home Gen AI\",\n",
        "    description=\"Write Your Prompt Here!\"\n",
        ").launch(share=True)\n"
      ],
      "metadata": {
        "id": "LeBZgQntCIPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v6rs4_fJAtV1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}